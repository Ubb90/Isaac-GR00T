apiVersion: batch/v1
kind: Job
metadata:
  generateName: groot-finetune-
  namespace: pgr25florent
spec:
  backoffLimit: 0 # Don't retry automatically if code fails
  template:
    spec:
      serviceAccountName: containerroot
 
      # Hardware Request
      nodeSelector:
        nvidia.com/gpu.product: "NVIDIA-RTX-A6000"
 
      volumes:
      # 1. Output Storage (Personal)
      - name: personal-storage
        persistentVolumeClaim:
          claimName: pgr25florentvol1claim
      
      - name: ssh-key
        secret:
          secretName: launcher-ssh-key
          defaultMode: 256

      # 2. Input Data Storage (Shared)
      - name: shared-storage
        persistentVolumeClaim:
          claimName: pgr25florent-datasets-claim
 
      - name: dshm
        emptyDir:
          medium: Memory
 
      containers:
      - name: trainer
        image: docker.io/fkgsoftware/groot-finetune:v1
        imagePullPolicy: Always
 
        securityContext:
          runAsUser: 0
 
        resources:
          requests:
            cpu: "4"
            memory: "8Gi"
            nvidia.com/gpu: "1"
          limits:
            cpu: "64"
            memory: "64Gi"
            nvidia.com/gpu: "1"
 
        volumeMounts:
        - name: personal-storage
          mountPath: /data
        - name: shared-storage
          mountPath: /mnt/datasets
          readOnly: true
        - name: dshm
          mountPath: /dev/shm
        - name: ssh-key
          mountPath: /root/.ssh
        env:
        - name: WANDB_PROJECT
          value: "groot-static"
        - name: WANDB_MODE
          value: "online"
        - name: PYTHONUNBUFFERED
          value: "1"
        envFrom:
        - secretRef:
            name: launcher-global-env

        command: ["/bin/bash", "-c"]
        args:
          - |
            echo "--- STARTING GR00T FINETUNE ---"
            nvidia-smi
            git remote remove origin
            git remote add origin https://github.com/Ubb90/Isaac-GR00T.git
            git stash
            git pull origin main
            # 1. Verify Dataset Path before starting
            DATASET_PATH="/mnt/datasets/letrack/so101track_cube_static_reduced_50_lerobot_v2/"
            FOLDER_NAME=$(echo "${DATASET_PATH%/}" | sed 's/.*\///; s/_lerobot_v[^/]*$//')

            if [ ! -d "$DATASET_PATH" ]; then
              echo "ERROR: Dataset not found at $DATASET_PATH"
              echo "Listing /mnt/datasets/letrack to help debug:"
              ls -F /mnt/datasets/letrack/
              exit 1
            fi
 
            echo "Dataset found at: $DATASET_PATH"
 
            # 2. Create Output Directory on Personal Storage
            OUTPUT_DIR="/data/groot/${FOLDER_NAME}"
            mkdir -p "$OUTPUT_DIR"

            # 3. Run Training
            python scripts/gr00t_finetune.py \
              --dataset-path "$DATASET_PATH" \
              --output-dir "${OUTPUT_DIR}" \
              --num-gpus 1 \
              --max-steps 5000 \
              --batch-size 48 \
              --learning_rate 1e-5 \
              --video-backend torchvision_av \
              --data-config so100_track\
              --save-steps 500 \
              2>&1 | tee "$OUTPUT_DIR/training_log.txt"

            python scripts/gr00t_finetune.py \
              --dataset-path "$DATASET_PATH" \
              --output-dir "${OUTPUT_DIR}_medium" \
              --num-gpus 1 \
              --max-steps 5000 \
              --batch-size 48 \
              --learning_rate 1e-5 \
              --video-backend torchvision_av \
              --data-config so100_track_medium\
              --save-steps 500 \
              2>&1 | tee "$OUTPUT_DIR/training_log_medium.txt"
              
            python scripts/gr00t_finetune.py \
              --dataset-path "$DATASET_PATH" \
              --output-dir "${OUTPUT_DIR}_long" \
              --num-gpus 1 \
              --max-steps 5000 \
              --batch-size 48 \
              --learning_rate 1e-5 \
              --video-backend torchvision_av \
              --data-config so100_track_long\
              --save-steps 500 \
              2>&1 | tee "$OUTPUT_DIR/training_log_long.txt"


      restartPolicy: OnFailure